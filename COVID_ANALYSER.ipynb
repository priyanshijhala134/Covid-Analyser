import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from keras.models import Sequential
from keras.layers import Dense

# Load your CSV file
df = pd.read_csv('/content/Country-wise-COVID-cases.csv')
df.head()

df.dropna(inplace=True)
data = df.drop(columns=['Country Name']) #dropping this column for numerical analysis

# Standardize the data
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Use the Elbow Method to find optimal clusters
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=0)
    kmeans.fit(data_scaled)
    wcss.append(kmeans.inertia_)

plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

# Let's choose 3 clusters based on the Elbow plot
kmeans = KMeans(n_clusters=3, random_state=0)
clusters = kmeans.fit_predict(data_scaled)
df['Cluster'] = clusters

sns.scatterplot(data=df, x='Total Infected', y='Total Deaths', hue='Cluster', palette='Set1')
plt.title('K-Means Clustering of COVID-19 Data')
plt.show()

X = df[['Total Infected']]
y = df['Total Deaths']

model = LinearRegression()
model.fit(X, y)

# Plot
plt.scatter(X, y, color='blue')
plt.plot(X, model.predict(X), color='red')
plt.xlabel("Total Infected")
plt.ylabel("Total Deaths")
plt.title("Linear Regression - Infections vs Deaths")
plt.show()

# Predict deaths for new data
new_infections = np.array([[1000000]])
predicted_deaths = model.predict(new_infections)
print(f"Predicted deaths for 1,000,000 infections: {predicted_deaths[0]}")

# Features: Total Infected, Total Deaths
# Target: Recovered %
X_nn = df[['Total Infected', 'Total Deaths']]
y_nn = df['Recovered %']

X_train, X_test, y_train, y_test = train_test_split(X_nn, y_nn, test_size=0.2, random_state=42)

# Normalize
scaler_nn = StandardScaler()
X_train = scaler_nn.fit_transform(X_train)
X_test = scaler_nn.transform(X_test)

# Build the neural network
model_nn = Sequential()
model_nn.add(Dense(16, input_dim=2, activation='relu'))
model_nn.add(Dense(8, activation='relu'))
model_nn.add(Dense(1))  # Output layer

model_nn.compile(optimizer='adam', loss='mean_squared_error')
model_nn.fit(X_train, y_train, epochs=100, verbose=0)

# Evaluate
loss = model_nn.evaluate(X_test, y_test)
print(f"Neural Network Test Loss: {loss:.4f}")

# Predict recovery %
new_data = scaler_nn.transform([[1000000, 50000]])  # 1M infected, 50k deaths
predicted_recovery = model_nn.predict(new_data)
print(f"Predicted Recovery %: {predicted_recovery[0][0]:.2f}")

from sklearn.metrics import silhouette_score

score = silhouette_score(data_scaled, clusters)
print(f'Silhouette Score: {score:.2f}')

from sklearn.metrics import r2_score

y_pred = model.predict(X)
r2 = r2_score(y, y_pred)
print(f'R² Score: {r2:.2f}')

y_pred_nn = model_nn.predict(X_test)

# R² Score for NN
r2_nn = r2_score(y_test, y_pred_nn)
print(f'Neural Network R² Score: {r2_nn:.2f}')

plt.scatter(y_test, y_pred_nn)
plt.xlabel('Actual Recovered %')
plt.ylabel('Predicted Recovered %')
plt.title('Actual vs Predicted - Neural Network')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.show()
